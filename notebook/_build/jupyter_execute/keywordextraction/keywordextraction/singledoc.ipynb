{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdWZnkZksb0S"
   },
   "source": [
    "# Tfidf and RAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIyVa8GrssOz"
   },
   "source": [
    "## Downdload dataset: [Inspec](https://dl.acm.org/doi/10.3115/1119355.1119383)\n",
    "\n",
    "Inspec consists of 2,000 abstracts of scientific journal papers from Computer Science collected between the years 1998 and 2002. Each document has two sets of keywords assigned: the controlled keywords, which are manually controlled assigned keywords that appear in the Inspec thesaurus but may not appear in the document, and the uncontrolled keywords which are freely assigned by the editors, i.e., are not restricted to the thesaurus or to the document. In our repository, we consider a union of both sets as the ground-truth .[[Download source]](https://github.com/LIAAD/KeywordExtractor-Datasets#inspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_HMOgHRg7Q6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 10:59:28--  https://github.com/LIAAD/KeywordExtractor-Datasets/raw/master/datasets/Inspec.zip\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving github.com (github.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.69.186.44\r\n",
      "Connecting to github.com (github.com)|52.69.186.44|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\r\n",
      "Location: https://raw.githubusercontent.com/LIAAD/KeywordExtractor-Datasets/master/datasets/Inspec.zip [following]\r\n",
      "--2021-02-02 10:59:28--  https://raw.githubusercontent.com/LIAAD/KeywordExtractor-Datasets/master/datasets/Inspec.zip\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.101.88.133\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.88.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 1890788 (1.8M) [application/zip]\r\n",
      "Saving to: â€˜Inspec.zipâ€™\r\n",
      "\r\n",
      "\r",
      "Inspec.zip            0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip            8%[>                   ] 153.41K   629KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip           17%[==>                 ] 331.04K   746KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip           40%[=======>            ] 749.23K  1.13MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip           62%[===========>        ]   1.13M  1.33MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip           89%[================>   ]   1.61M  1.52MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Inspec.zip          100%[===================>]   1.80M  1.60MB/s    in 1.1s    \r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-02 10:59:30 (1.60 MB/s) - â€˜Inspec.zipâ€™ saved [1890788/1890788]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/LIAAD/KeywordExtractor-Datasets/raw/master/datasets/Inspec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hcQUcp257dxE"
   },
   "outputs": [],
   "source": [
    "!unzip -q Inspec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oXLN2Pk74b3",
    "outputId": "5bc7ae3f-b97e-4009-b747-30f56045e136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make data: DONE\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "docsPaths = listdir('Inspec/docsutf8')\n",
    "data = []\n",
    "for p in docsPaths:\n",
    "  textPath = 'Inspec/docsutf8/'+p\n",
    "  keyPath = 'Inspec/keys/'+p[:-3]+'key'\n",
    "  with open(textPath) as fi:\n",
    "    text = fi.read()\n",
    "  with open(keyPath) as fi:\n",
    "    key = fi.read()\n",
    "  data.append({'text':text, 'key':key})\n",
    "print(\"make data: DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUN91JS4ta1e",
    "outputId": "491693c1-40bd-46b2-f2f7-87dba52d71f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of texts in the dataset: 2000\n",
      "data[1000]:\n",
      "\n",
      " Color plane interpolation using alternating projections\n",
      "Most commercial digital cameras use color filter arrays to sample red, green,\n",
      "\tand blue colors according to a specific pattern. At the location of\n",
      "\teach pixel only one color sample is taken, and the values of the other\n",
      "\tcolors must be interpolated using neighboring samples. This color plane\n",
      "\tinterpolation is known as demosaicing; it is one of the important tasks\n",
      "\tin a digital camera pipeline. If demosaicing is not performed\n",
      "\tappropriately, images suffer from highly visible color artifacts. In\n",
      "\tthis paper we present a new demosaicing technique that uses\n",
      "\tinter-channel correlation effectively in an alternating-projections\n",
      "\tscheme. We have compared this technique with six state-of-the-art\n",
      "\tdemosaicing techniques, and it outperforms all of them, both visually\n",
      "\tand in terms of mean square error\n",
      "\n",
      "\n",
      "\n",
      "keywords:\n",
      "\n",
      "color plane interpolation\n",
      "alternating projections\n",
      "digital cameras\n",
      "demosaicing\n",
      "color filter arrays\n",
      "color artifacts\n",
      "inter-channel correlation\n",
      "cameras\n",
      "correlation methods\n",
      "image colour analysis\n",
      "interpolation\n",
      "optical filters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of texts in the dataset:\",len(data))\n",
    "print(\"data[1000]:\\n\\n\",data[1000]['text'])\n",
    "print(\"\\n\\nkeywords:\\n\")\n",
    "for i in data[1000]['key'].replace('\\t','').split(\"\\n\"):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoEXE5_Fs19v"
   },
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "\n",
    "In text preprocessing we : \n",
    "\n",
    "*   convert to lowercase\n",
    "*   remove tages\n",
    "*   remove special characters and digits\n",
    "*   remove [stopwords](https://en.wikipedia.org/wiki/Stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk  # install nltk if you have not done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igGNrEH3-h_z",
    "outputId": "7ed60445-a65d-444d-ddaf-da017719091b"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('stopwords') # uncomment to download stopwords\n",
    "#nltk.download('wordnet') # uncomment to download wordnet\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uis3S4YT-sB3"
   },
   "outputs": [],
   "source": [
    "def preprocess(input_text):\n",
    "    input_text = input_text.lower()\n",
    "    input_text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \", input_text)\n",
    "    input_text = re.sub(\"(\\\\d|\\\\W)+\",\" \", input_text)\n",
    "    text_string = input_text.split()\n",
    "    text_string = [word for word in text_string if word not in stopwords_set]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_string = [lemmatizer.lemmatize(word) for word in text_string]\n",
    "    return ' '.join(text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GI-ypX6S-tLS",
    "outputId": "ac3b1271-2309-44c7-bea2-c117374b8b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "docs = [preprocess(x['text']) for x in data]\n",
    "keys = [x['key'].replace('\\t','').split('\\n')[:-1] for x in data]\n",
    "print(len(docs),len(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuByKGZRs5OE"
   },
   "source": [
    "## TF-IDF based method\n",
    "\n",
    "In this method, each word in text(tokenized string list) is consider as a candidate. Score of cadidate keyword is define by [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) score. The k candidate keywords with the highest TF-IDF score are selected as keywords.\n",
    "\n",
    "TF-IDF(term frequencyâ€“inverse document frequency) is a numerical statistic which reflect the importance of word in a text while considering it occurence within a group of documents(corpus).\n",
    "\n",
    "Consider a corpus with $N$ documents. Let $t_{i,j}$ be frequency of term $w_i (i=1,\\cdots,W)$ in document $D_j$ and $df_i$ be number of documents which term $w_i$ occurences in. TF-IDF score of term $w_i$ is defined by $\\operatorname{tfidf}(i)$.\n",
    "\n",
    "$$\n",
    "\\operatorname{tfidf}(i) = \\sum_{j=1}^{N} t_{i,j}\\log{\\frac{N}{df_i}}\n",
    "$$\n",
    "\n",
    "In the following implimentation, we use tools offered by *scikitlearn*.\n",
    "\n",
    "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn-feature-extraction-text-countvectorizer)     \n",
    "[TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn # uncomment to install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DxRv1szqBYxd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrwrCRrHBcHQ",
    "outputId": "8590d3c0-ddb2-46f9-98b5-73dc174ecb94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.95, max_features=20000, ngram_range=(1,4))\n",
    "word_freq_vec = vectorizer.fit_transform(docs)\n",
    "transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "transformer.fit(word_freq_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Zx6WMM0WBfhg"
   },
   "outputs": [],
   "source": [
    "def extract_topk(features, sorted_words, k=10):\n",
    "    sorted_words = sorted_words[:k]\n",
    "    scores = []\n",
    "    f_list = []\n",
    "    for i, score in sorted_words:\n",
    "        scores.append(round(score, 3))\n",
    "        f_list.append(features[i])\n",
    "    result = {}\n",
    "    for i in range(len(f_list)):\n",
    "        result[f_list[i]] = scores[i]\n",
    "    return result\n",
    "\n",
    "def get_keywords(idx, docs):\n",
    "    tfidf_vec = transformer.transform(vectorizer.transform([docs[idx]]))\n",
    "    co_matrix = tfidf_vec.tocoo()\n",
    "    sorted_words = sorted(zip(co_matrix.col, co_matrix.data), key=lambda x: (x[1],x[0]), reverse=True)\n",
    "    features = vectorizer.get_feature_names()\n",
    "    keywords = extract_topk(features, sorted_words, 10)\n",
    "    return keywords\n",
    "\n",
    "def print_keywords(idx, keywords, data, ans):\n",
    "    ans = [preprocess(a) for a in ans[:len(keywords)]]\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(data[idx]['text'])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        if k in ans:\n",
    "          print(\"ðŸŸ¢\",end='')\n",
    "        print(k,keywords[k])\n",
    "    print(\"\\n===Keywords by Author===\")\n",
    "    ext_keys = [i for i in keywords]\n",
    "    for i in ans:\n",
    "      if i in ext_keys:\n",
    "          print(\"ðŸ™†â€â™‚ï¸\",end=\"\")\n",
    "      print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f0ZAmpbBjvs",
    "outputId": "202ccf3e-f485-4b66-e401-b80ca85440bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Abstract=====\n",
      "Fractional differentiation in passive vibration control\n",
      "From a single-degree-of-freedom model used to illustrate the concept of\n",
      "\tvibration isolation, a method to transform the design for a suspension\n",
      "\tinto a design for a robust controller is presented. Fractional\n",
      "\tdifferentiation is used to model the viscoelastic behaviour of the\n",
      "\tsuspension. The use of fractional differentiation not only permits\n",
      "\toptimisation of just four suspension parameters, showing the\n",
      "\t'compactness' of the fractional derivative operator, but also leads to\n",
      "\trobustness of the suspension's performance to uncertainty of the sprung\n",
      "\tmass. As an example, an engine suspension is studied\n",
      "\n",
      "\n",
      "===Keywords===\n",
      "ðŸŸ¢suspension 0.537\n",
      "fractional 0.353\n",
      "ðŸŸ¢fractional differentiation 0.341\n",
      "ðŸŸ¢differentiation 0.289\n",
      "vibration 0.164\n",
      "ðŸŸ¢vibration isolation 0.118\n",
      "use fractional 0.118\n",
      "single degree freedom 0.118\n",
      "single degree 0.118\n",
      "operator also 0.118\n",
      "\n",
      "===Keywords by Author===\n",
      "ðŸ™†â€â™‚ï¸fractional differentiation\n",
      "passive vibration control\n",
      "ðŸ™†â€â™‚ï¸vibration isolation\n",
      "ðŸ™†â€â™‚ï¸suspension\n",
      "robust controller\n",
      "viscoelastic behaviour\n",
      "sprung mass\n",
      "engine suspension\n",
      "damping\n",
      "ðŸ™†â€â™‚ï¸differentiation\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 238\n",
    "keywords=get_keywords(sample_idx, docs)\n",
    "print_keywords(sample_idx,keywords, data, keys[sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuyMHTb-Dtia"
   },
   "source": [
    "With this method, four of extracted top ten keywords are in keywords set selected by author. This result is somehow acceptable. However, to calculate TF-IDF score, a collection of documents(corpus) is required as reference data. Therefore, characteristic of reference data(corpus) highly affect the importance of word in single document. Keywords that occur in many documents within the corpus are not likely to be selected as statistically discriminating by lowering the TF-IDF score value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qis1Ijd5tBCD"
   },
   "source": [
    "## RAKE: Rapid Automatic Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZZhBM9hGwmK"
   },
   "source": [
    "*(Ref: Rose, Stuart & Engel, Dave & Cramer, Nick & Cowley, Wendy. (2010). [Automatic Keyword Extraction from Individual Documents](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents). 10.1002/9780470689646.ch1.)*\n",
    "\n",
    "\n",
    "\n",
    "RAKE is a keyword extraction method which is effectively operates on individual document. RAKE is based on an observation that keywords frequently contain multiple\n",
    "words but rarely contain standard punctuation or stop words.\n",
    "\n",
    "RAKE get a list of stop words, a\n",
    "set of phrase delimiters, and a set of word delimiters as inputs. Base on the information from stop words and\n",
    "phrase delimiters, RAKE makes partitions of the document text into candidate keywords. \n",
    "\n",
    "Next, co-occurrences graph of words\n",
    "within these candidate keywords are generated. This graph is significient in identifying word cooccurrence without the application of an arbitrarily sized sliding window. \n",
    "\n",
    "Several metrics are used for calculating word scores\n",
    "\n",
    "1.   word frequency : $freq(w)$\n",
    "2.   word degree : $deg(w)$\n",
    "3.   ratio of degree to frequency : $\\frac{deg(w)}{freq(w)}$\n",
    "\n",
    "In summary, $deg(w)$ favors words that occur often and in\n",
    "longer candidate keywords. Words\n",
    "that occur frequently regardless of the number of words with which they co-occur\n",
    "are favored by $freq(w)$. Words that\n",
    "predominantly occur in longer candidate keywords are favored by $deg(w)/freq(w)$ [[Ref]](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents).\n",
    "\n",
    "The score for each candidate keyword is computed as the sum of its member word scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMMZd2PRJ8_r"
   },
   "source": [
    "**Example of score calculation from  [Automatic Keyword Extraction from Individual Documents](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents)**\n",
    "\n",
    "Figures from Original Paper of [RAKE](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents)\n",
    "\n",
    "![fig 01](fig01.png)\n",
    "\n",
    "![fig 02](fig02.png)\n",
    "\n",
    "![fig 03](fig03.png)\n",
    "\n",
    "![fig 04](fig04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNYq81jqCVgu",
    "outputId": "26d13f07-615d-430a-dfe5-b3c2bfe50858"
   },
   "outputs": [],
   "source": [
    "# !pip install rake-nltk # uncomment to install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xMQ5BQHKG1A6"
   },
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-rQ85qEmG2gW"
   },
   "outputs": [],
   "source": [
    "def get_keywords_rake(docs, n=10):\n",
    "    rk = Rake()\n",
    "    rk.extract_keywords_from_text(docs)\n",
    "    keywords = rk.get_ranked_phrases_with_scores()[0:n]\n",
    "    return keywords\n",
    "\n",
    "def print_keywords_rake(idx, keywords, data, ans):\n",
    "    ans = [preprocess(a) for a in ans[:len(keywords)]]\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(data[idx]['text'])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        if k[1] in ans:\n",
    "          print(\"ðŸŸ¢\",end=\"\")\n",
    "        print(k[1],k[0])\n",
    "    print(\"\\n===Keywords by Author===\")\n",
    "    ext_keys = [i[1] for i in keywords]\n",
    "    for i in ans:\n",
    "      if i in ext_keys:\n",
    "          print(\"ðŸ™†â€â™‚ï¸\",end=\"\")\n",
    "      print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvXUCuiuHAf1",
    "outputId": "dcf1a4bf-2d5e-4cc7-c738-9b314c1f5d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Abstract=====\n",
      "Fractional differentiation in passive vibration control\n",
      "From a single-degree-of-freedom model used to illustrate the concept of\n",
      "\tvibration isolation, a method to transform the design for a suspension\n",
      "\tinto a design for a robust controller is presented. Fractional\n",
      "\tdifferentiation is used to model the viscoelastic behaviour of the\n",
      "\tsuspension. The use of fractional differentiation not only permits\n",
      "\toptimisation of just four suspension parameters, showing the\n",
      "\t'compactness' of the fractional derivative operator, but also leads to\n",
      "\trobustness of the suspension's performance to uncertainty of the sprung\n",
      "\tmass. As an example, an engine suspension is studied\n",
      "\n",
      "\n",
      "===Keywords===\n",
      "ðŸŸ¢passive vibration control 8.5\n",
      "fractional derivative operator 8.5\n",
      "four suspension parameters 8.0\n",
      "freedom model used 7.0\n",
      "ðŸŸ¢vibration isolation 4.5\n",
      "ðŸŸ¢fractional differentiation 4.5\n",
      "ðŸŸ¢viscoelastic behaviour 4.0\n",
      "ðŸŸ¢sprung mass 4.0\n",
      "ðŸŸ¢robust controller 4.0\n",
      "permits optimisation 4.0\n",
      "\n",
      "===Keywords by Author===\n",
      "ðŸ™†â€â™‚ï¸fractional differentiation\n",
      "ðŸ™†â€â™‚ï¸passive vibration control\n",
      "ðŸ™†â€â™‚ï¸vibration isolation\n",
      "suspension\n",
      "ðŸ™†â€â™‚ï¸robust controller\n",
      "ðŸ™†â€â™‚ï¸viscoelastic behaviour\n",
      "ðŸ™†â€â™‚ï¸sprung mass\n",
      "engine suspension\n",
      "damping\n",
      "differentiation\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 238\n",
    "keywords=get_keywords_rake(data[sample_idx]['text'])\n",
    "print_keywords_rake(sample_idx,keywords, data, keys[sample_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VstXC0bWMu0Q"
   },
   "source": [
    "Here we are! With this method, **six** of extracted top ten keywords are in keywords set selected by author. This is a great work!\n",
    "\n",
    "According to the [RAKE's paper](https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents), RAKE\n",
    "achieves higher precision and similar recall in comparison to existing techniques. RAKE takes a simple set of input parameters and automatically extracts keywords in a single pass, making it suitable for a wide\n",
    "range of documents and collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Abstract=====\n",
      "Fractional differentiation in passive vibration control\n",
      "From a single-degree-of-freedom model used to illustrate the concept of\n",
      "\tvibration isolation, a method to transform the design for a suspension\n",
      "\tinto a design for a robust controller is presented. Fractional\n",
      "\tdifferentiation is used to model the viscoelastic behaviour of the\n",
      "\tsuspension. The use of fractional differentiation not only permits\n",
      "\toptimisation of just four suspension parameters, showing the\n",
      "\t'compactness' of the fractional derivative operator, but also leads to\n",
      "\trobustness of the suspension's performance to uncertainty of the sprung\n",
      "\tmass. As an example, an engine suspension is studied\n",
      "\n",
      "\n",
      "===Keywords===\n",
      "ðŸŸ¢passive vibration control 8.5\n",
      "fractional derivative operator 8.5\n",
      "four suspension parameters 8.0\n",
      "freedom model used 7.0\n",
      "ðŸŸ¢vibration isolation 4.5\n",
      "ðŸŸ¢fractional differentiation 4.5\n",
      "ðŸŸ¢viscoelastic behaviour 4.0\n",
      "ðŸŸ¢sprung mass 4.0\n",
      "ðŸŸ¢robust controller 4.0\n",
      "permits optimisation 4.0\n",
      "\n",
      "===Keywords by Author===\n",
      "ðŸ™†â€â™‚ï¸fractional differentiation\n",
      "ðŸ™†â€â™‚ï¸passive vibration control\n",
      "ðŸ™†â€â™‚ï¸vibration isolation\n",
      "suspension\n",
      "ðŸ™†â€â™‚ï¸robust controller\n",
      "ðŸ™†â€â™‚ï¸viscoelastic behaviour\n",
      "ðŸ™†â€â™‚ï¸sprung mass\n",
      "engine suspension\n",
      "damping\n",
      "differentiation\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 238\n",
    "keywords=get_keywords_rake(data[sample_idx]['text'])\n",
    "print_keywords_rake(sample_idx,keywords, data, keys[sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We use Mean Average Precision(MAP) and Mean Reciprocal Rank(MRR) value as evaluation matrics.\n",
    "\n",
    "[[How to calculate MAP and MRR]](https://medium.com/gumgum-tech/exploring-different-keyword-extractors-evaluation-metrics-and-strategies-ef874d336773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPscore(y_true, y_pred):\n",
    "    rel = 0\n",
    "    pre = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] in y_true:\n",
    "            rel += 1\n",
    "            pre.append(rel/(i+1))\n",
    "    if rel>0:\n",
    "        return sum(pre)/len(pre)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def MRRscore(y_true, y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] in y_true:\n",
    "            break\n",
    "    return 1/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "test_num = 500\n",
    "test_sample_idx = list(range(2000-test_num,2000))\n",
    "print(len(test_sample_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 ms, sys: 52.8 ms, total: 702 ms\n",
      "Wall time: 759 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24264513794406672, 0.2639031746031743)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "MAPscores_rake = []\n",
    "MRRscores_rake = []\n",
    "\n",
    "for idx in test_sample_idx:\n",
    "    y_true = keys[idx]\n",
    "    keywords = get_keywords_rake(data[idx]['text'])\n",
    "    y_pred = [i[1] for i in keywords]\n",
    "    MAPscores_rake.append(MAPscore(y_true,y_pred))\n",
    "    MRRscores_rake.append(MRRscore(y_true,y_pred))\n",
    "sum(MAPscores_rake)/test_num,sum(MRRscores_rake)/test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 139 ms, total: 12.6 s\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17496984126984136, 0.24119365079364993)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "MAPscores_tfidf = []\n",
    "MRRscores_tfidf = []\n",
    "for idx in test_sample_idx:\n",
    "    y_true = keys[idx]\n",
    "    keywords = get_keywords(idx, docs)\n",
    "    y_pred = [i for i in keywords]\n",
    "    MAPscores_tfidf.append(MAPscore(y_true,y_pred))\n",
    "    MRRscores_tfidf.append(MRRscore(y_true,y_pred))\n",
    "sum(MAPscores_tfidf)/test_num,sum(MRRscores_tfidf)/test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "keywordExtraction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}